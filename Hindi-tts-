{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11033207,"sourceType":"datasetVersion","datasetId":6871836}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle's secrets management to securely access your Hugging Face token!","metadata":{}},{"cell_type":"markdown","source":"# 1Ô∏è‚É£ Install kokoro\n","metadata":{}},{"cell_type":"code","source":"!pip install -q kokoro>=0.8.2 soundfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:25:30.005988Z","iopub.execute_input":"2025-03-14T13:25:30.006359Z","iopub.status.idle":"2025-03-14T13:25:43.197600Z","shell.execute_reply.started":"2025-03-14T13:25:30.006330Z","shell.execute_reply":"2025-03-14T13:25:43.196129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2Ô∏è‚É£ Install espeak, used for English OOD fallback and some non-English languages\n","metadata":{}},{"cell_type":"code","source":"\n!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n# üá™üá∏ 'e' => Spanish es\n# üá´üá∑ 'f' => French fr-fr\n# üáÆüá≥ 'h' => Hindi hi\n# üáÆüáπ 'i' => Italian it\n# üáßüá∑ 'p' => Brazilian Portuguese pt-br","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:25:55.988173Z","iopub.execute_input":"2025-03-14T13:25:55.988536Z","iopub.status.idle":"2025-03-14T13:26:07.981756Z","shell.execute_reply.started":"2025-03-14T13:25:55.988503Z","shell.execute_reply":"2025-03-14T13:26:07.980483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3Ô∏è‚É£ Initalize a pipeline","metadata":{}},{"cell_type":"code","source":"from kokoro import KPipeline\nfrom IPython.display import display, Audio\nimport soundfile as sf\n# üá∫üá∏ 'a' => American English, üá¨üáß 'b' => British English\n# üáØüáµ 'j' => Japanese: pip install misaki[ja]\n# üá®üá≥ 'z' => Mandarin Chinese: pip install misaki[zh]\npipeline = KPipeline(lang_code='hi') # <= make sure lang_code matches voice (hi or h for hindi)\n\n# Write your text here after '''\ntext = '''\n\n\n‡§™‡§Ç‡§ú‡§æ‡§¨ ‡§ï‡•á ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§ó‡§æ‡§Å‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§π‡§µ‡•á‡§≤‡•Ä ‡§•‡•Ä‡•§\n\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:26:14.344366Z","iopub.execute_input":"2025-03-14T13:26:14.344751Z","iopub.status.idle":"2025-03-14T13:26:22.459744Z","shell.execute_reply.started":"2025-03-14T13:26:14.344718Z","shell.execute_reply":"2025-03-14T13:26:22.458905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4Ô∏è‚É£ Generate, display, and save audio files in a loop.","metadata":{}},{"cell_type":"code","source":"generator = pipeline(\n    text, voice='hm_omega', # <= change voice here voice code (Male => hm_omega, hm_psi and Female=> hf_alpha, hf_beta)\n    speed=1, split_pattern=r'\\n+' #speed 0.1 to 1\n)\nfor i, (gs, ps, audio) in enumerate(generator):\n    print(i)  # i => index\n    print(gs) # gs => graphemes/text\n    print(ps) # ps => phonemes\n    display(Audio(data=audio, rate=24000, autoplay=i==0))\n    sf.write(f'{i}.wav', audio, 24000) # save each audio file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:26:54.298249Z","iopub.execute_input":"2025-03-14T13:26:54.298618Z","iopub.status.idle":"2025-03-14T13:26:59.411826Z","shell.execute_reply.started":"2025-03-14T13:26:54.298586Z","shell.execute_reply":"2025-03-14T13:26:59.410730Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5Ô∏è‚É£ Added gradio tunnel for gui interface ","metadata":{}},{"cell_type":"code","source":"!pip install kokoro>=0.8.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T18:17:27.370801Z","iopub.execute_input":"2025-03-14T18:17:27.371192Z","iopub.status.idle":"2025-03-14T18:17:40.073718Z","shell.execute_reply.started":"2025-03-14T18:17:27.371161Z","shell.execute_reply":"2025-03-14T18:17:40.072356Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install gradio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T18:16:31.857527Z","iopub.execute_input":"2025-03-14T18:16:31.858033Z","iopub.status.idle":"2025-03-14T18:16:36.493616Z","shell.execute_reply.started":"2025-03-14T18:16:31.857988Z","shell.execute_reply":"2025-03-14T18:16:36.491808Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.21.0)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.11)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\nRequirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.7.2)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a2)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.11.0)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.46.1)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (2024.12.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (14.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.29.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import gradio as gr\nfrom kokoro import KPipeline\n\n# Initialize pipeline\npipeline = KPipeline(lang_code=\"hi\")\n\n# Function to generate speech\ndef hindi_tts(text, voice, speed):\n    try:\n        print(f\"Processing: {text} | Voice: {voice} | Speed: {speed}\")\n        generator = pipeline(text, voice=voice, speed=speed, split_pattern=r'\\n+')\n        audio_data = None\n        \n        # Generate speech\n        for gs, ps, audio in generator:\n            audio_data = audio  # Store last generated audio\n        \n        # üî• Fix: Ensure audio_data is converted to NumPy array\n        if audio_data is not None:\n            return (24000, audio_data.numpy())  # Convert to NumPy\n        else:\n            return \"Error: No audio generated. Try different input.\"\n    \n    except Exception as e:\n        print(f\"Gradio Error: {e}\")\n        return f\"Error: {str(e)}\"\n\n# Gradio UI\niface = gr.Interface(\n    fn=hindi_tts,\n    inputs=[\n        gr.Textbox(label=\"Enter Hindi Text\", placeholder=\"‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§≤‡§ø‡§ñ‡•á‡§Ç...\"),\n        gr.Radio(choices=[\"hm_omega\", \"hm_psi\", \"hf_alpha\", \"hf_beta\"], label=\"Select Voice\", value=\"hf_alpha\"),\n        gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label=\"Speech Speed\", value=1.0)\n    ],\n    outputs=gr.Audio(label=\"Generated Speech\"),\n    title=\"Hindi Text-to-Speech\",\n    description=\"Enter Hindi text and generate speech using Kokoro TTS.\",\n    allow_flagging=\"never\"\n)\n\n# Launch Gradio\niface.launch(share=True)\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n/usr/local/lib/python3.10/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://14d13c0d320e09e8b7.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://14d13c0d320e09e8b7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"# working directory ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport soundfile as sf\nimport tempfile\nimport gradio as gr\nfrom transformers import pipeline\n\n# ‚úÖ Load Hugging Face SpeechT5 TTS Model\nhindi_tts = pipeline(\"text-to-speech\", model=\"microsoft/speecht5_tts\")\n\n# ‚úÖ Load RVC Model (Replace with your model path)\nrvc_model_path = \"/kaggle/input/datsets/DeepMale.pth\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntry:\n    rvc_model = torch.load(rvc_model_path, map_location=device)\n    rvc_model.eval()  # Set model to evaluation mode\n    print(\"‚úÖ RVC Model Loaded Successfully!\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Error Loading RVC Model: {str(e)}\")\n\ndef apply_rvc_conversion(audio_array, sr=24000):\n    \"\"\"\n    Apply RVC voice conversion to the generated TTS audio.\n    \"\"\"\n    try:\n        audio_tensor = torch.tensor(audio_array, dtype=torch.float32).to(device)\n\n        # Ensure correct shape (batch, channels, samples)\n        if len(audio_tensor.shape) == 1:\n            audio_tensor = audio_tensor.unsqueeze(0)\n\n        # Apply voice conversion\n        with torch.no_grad():\n            converted_audio = rvc_model(audio_tensor)\n\n        # Convert tensor back to numpy array\n        converted_audio_np = converted_audio.squeeze(0).cpu().numpy()\n\n        # Save converted audio\n        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n        sf.write(temp_file.name, converted_audio_np, sr)\n\n        return temp_file.name  # Return file path\n    \n    except Exception as e:\n        return f\"Error in RVC conversion: {str(e)}\"\n\ndef generate_tts_and_convert(text, apply_rvc):\n    \"\"\"\n    Generate Hindi TTS and optionally apply RVC voice conversion.\n    \"\"\"\n    try:\n        # Generate TTS audio\n        generator = hindi_tts(text)\n        audio_data = np.array(generator[\"audio\"], dtype=np.float32)\n\n        # Apply RVC if selected\n        if apply_rvc:\n            return apply_rvc_conversion(audio_data)\n        \n        # Save and return TTS audio\n        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n        sf.write(temp_file.name, audio_data, 24000)\n        return temp_file.name\n    \n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n# ‚úÖ Gradio Interface\niface = gr.Interface(\n    fn=generate_tts_and_convert,\n    inputs=[\n        gr.Textbox(label=\"Enter Hindi Text\"),\n        gr.Checkbox(label=\"Apply RVC Voice Conversion\", value=False)\n    ],\n    outputs=gr.File(label=\"Download Processed Speech\"),\n    title=\"Hindi TTS with RVC Voice Cloning\",\n    description=\"Enter text, generate Hindi speech, and apply RVC voice cloning.\"\n)\n\niface.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T18:27:12.030666Z","iopub.execute_input":"2025-03-14T18:27:12.031110Z","iopub.status.idle":"2025-03-14T18:27:21.270652Z","shell.execute_reply.started":"2025-03-14T18:27:12.031078Z","shell.execute_reply":"2025-03-14T18:27:21.269462Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fee9a805e1e4e8a9adf4a60f6bdb1d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/585M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"432b327856e1414f9f14173707cdf728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/232 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5689eb5c464b55aa13fca4ff267c15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm_char.model:   0%|          | 0.00/238k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab378bbbf01343dc97258e5d06974f93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae155effabc4540b1d90cdf3b8c7e1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5f1128247924870bcd4c00a8a63c3f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258b32c030b14e86b9d76d4417807d4f"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ff94b6f2a2c4256be3da64bf9d8bc0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/50.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620a9ef4f0cb4488975f5e888458f986"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-22-bd2229b293aa>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  rvc_model = torch.load(rvc_model_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"‚ö†Ô∏è Error Loading RVC Model: 'collections.OrderedDict' object has no attribute 'eval'\n* Running on local URL:  http://127.0.0.1:7861\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://22edd91a37f2438c8d.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://22edd91a37f2438c8d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 625, in process_events\n    response = await route_utils.call_process_api(\n  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n    output = await app.get_blocks().process_api(\n  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2113, in process_api\n    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1919, in postprocess_data\n    prediction_value = block.postprocess(prediction_value)\n  File \"/usr/local/lib/python3.10/dist-packages/gradio/components/file.py\", line 223, in postprocess\n    size=Path(value).stat().st_size,\n  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\nFileNotFoundError: [Errno 2] No such file or directory: 'Error: `speaker_embeddings` must be specified. For example, you can use a speaker embeddings by following\\n                    the code snippet provided in this link:\\n                    https:/huggingface.co/datasets/Matthijs/cmu-arctic-xvectors\\n                    '\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import gradio as gr\nimport numpy as np\nfrom kokoro import KPipeline\n\n# Initialize pipeline\npipeline = KPipeline(lang_code=\"hi\")\n\n# Function to generate speech\ndef hindi_tts(text, voice, speed):\n    try:\n        print(f\"Processing: {text} | Voice: {voice} | Speed: {speed}\")\n        generator = pipeline(text, voice=voice, speed=speed, split_pattern=r'\\n+')\n        audio_data = None\n        \n        # Generate speech and extract audio data\n        for gs, ps, audio in generator:\n            audio_data = audio  # Store last generated audio\n        \n        # Ensure valid audio output\n        if audio_data is not None:\n            audio_np = np.array(audio_data)  # Convert to NumPy array\n            return (24000, audio_np)  # Return as (sample_rate, audio)\n        else:\n            return \"Error: No audio generated. Try different input.\"\n    \n    except Exception as e:\n        print(f\"Gradio Error: {e}\")\n        return f\"Error: {str(e)}\"\n\n# Gradio UI\niface = gr.Interface(\n    fn=hindi_tts,\n    inputs=[\n        gr.Textbox(label=\"Enter Hindi Text\", placeholder=\"‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§≤‡§ø‡§ñ‡•á‡§Ç...\"),\n        gr.Radio(choices=[\"hm_omega\", \"hm_psi\", \"hf_alpha\", \"hf_beta\"], label=\"Select Voice\", value=\"hf_alpha\"),\n        gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label=\"Speech Speed\", value=1.0)\n    ],\n    outputs=gr.Audio(label=\"Generated Speech\"),\n    title=\"Hindi Text-to-Speech\",\n    description=\"Enter Hindi text and generate speech using Kokoro TTS.\",\n    allow_flagging=\"never\"\n)\n\n# Launch Gradio\niface.launch(share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T18:44:55.247259Z","iopub.execute_input":"2025-03-14T18:44:55.247670Z","iopub.status.idle":"2025-03-14T18:45:00.604582Z","shell.execute_reply.started":"2025-03-14T18:44:55.247629Z","shell.execute_reply":"2025-03-14T18:45:00.603407Z"}},"outputs":[{"name":"stdout","text":"WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n/usr/local/lib/python3.10/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7863\n* Running on public URL: https://67d5081efcb80ddd48.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://67d5081efcb80ddd48.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"Processing: ‡§™‡§Ç‡§ú‡§æ‡§¨ ‡§ï‡•á ‡§è‡§ï ‡§õ‡•ã‡§ü‡•á ‡§∏‡•á ‡§ó‡§æ‡§Å‡§µ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§π‡§µ‡•á‡§≤‡•Ä ‡§•‡•Ä‡•§ | Voice: hm_omega | Speed: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"hm_omega.pt:   0%|          | 0.00/523k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"835fc434c82548c086d483228a89b410"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:749: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n  warnings.warn(warning.format(data.dtype))\n","output_type":"stream"}],"execution_count":24}]}